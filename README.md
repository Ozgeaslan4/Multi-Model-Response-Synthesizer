This project involves an asynchronous Python script that integrates multiple large language models (LLMs) to generate a high-quality response to a user's query. The script first fetches a list of available models from an API, then selects specific models based on their names, such as "gpt-" or "TheBloke." Using these models, it sends the user prompt to each one and gathers their responses.

After collecting the responses, the script uses an aggregator model, "mistralai/Mixtral-8x22B-Instruct-v0.1," to synthesize a final response. The aggregator critically evaluates the inputs from the models, ensuring the output is coherent, refined, and reliable. The project leverages asyncio and aiohttp for asynchronous tasks, optimizing the process by handling multiple API calls simultaneously.
